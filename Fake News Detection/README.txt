Fake News Detector was built on the LIAR dataset for binary fake news detection  the results highlight the challenges of class imbalance and the need for models that can generalize beyond predicting the majority class. Experiments on the LIAR dataset for binary fake news classification reveal how severely class imbalance affects model performance and expose the limitations of approaches that rely on majority-class predictions. Among the evaluated methods, XGBoost performs comparatively better than the others, showing a precision of 0.28 for the real news class and demonstrating a limited but nonzero ability to recognize minority instances. According to its confusion matrix, the model correctly classifies 5 out of 208 real news articles, while the remainder are mislabeled. Although the recall for class 1 remains very low at 0.02, this still reflects some degree of separation between fake and real news. The reported accuracy of 83% is inflated by the dominance of fake news samples and therefore does not reflect meaningful classification quality; nonetheless, XGBoost maintains the most balanced performance across models. In contrast, the Random Forest classifier exhibits weaker results, correctly identifying only 2 real news cases and achieving a recall of 0.01 for class 1, indicating a strong bias toward the majority class despite its typical strength in general-purpose classification. Naïve Bayes, which often performs well in text-based tasks, fails entirely in this setting by assigning all samples to the fake news category, leading to zero precision and recall for real news. Logistic Regression shows the same behavior, offering no capability to detect real news instances. Although both Naïve Bayes and Logistic Regression reach accuracy levels around 83–84%, this outcome is solely driven by majority-class predictions and offers no practical value for identifying real news. Overall, XGBoost emerges as the strongest of the four models, though its effectiveness remains limited. These results point to deeper challenges within the dataset, including severe class imbalance and potentially complex linguistic differences between fake and real news. High accuracy coupled with extremely poor recall for the minority class suggests that the models are effectively overfitting to the dominant class. Given the importance of correctly identifying real news in fake news detection tasks, evaluation metrics such as recall, precision for class 1, and F1-score provide far more insight than accuracy alone. Consequently, while XGBoost can serve as a baseline, the findings highlight the need for improved techniques, including class rebalancing methods, enhanced feature representations, or more advanced models such as transformer-based architectures. In summary, despite ranking highest among the tested approaches, XGBoost’s limited success underscores that the current models are insufficient for reliable fake news detection, and future work must focus on addressing imbalance and leveraging context-aware representations to achieve meaningful progress.
